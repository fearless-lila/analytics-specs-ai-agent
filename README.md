# Analytics Requirements AI Agent

This Python-based AI agent automatically generates **analytics requirements** using a **Retrieval-Augmented Generation (RAG)** approach.  
By leveraging historical requirements as context, it produces more accurate, consistent, and contextually relevant outputs for analytics projects.

---

## âœ¨ Features

- ğŸ§  **Context-Aware Generation** â€” uses historical requirements as a retrieval base to enrich new outputs  
- ğŸ’¾ **Separation of Data** â€” keeps generated requirements and source data stored independently  
- ğŸ§© **Prompt Templates** â€” ensures consistent phrasing and formatting across generated requirements  
- ğŸ”Œ **Extendable Design** â€” can integrate easily with analytics, BI, or data engineering workflows  
- âš™ï¸ **Configurable Retrieval** â€” supports modular vector stores (e.g., FAISS, Chroma, Pinecone)

---

## ğŸ—‚ Project Structure

```
analytics-requirements-ai-agent/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ historical_requirements/     # Existing reference documents
â”‚   â””â”€â”€ generated_requirements/      # Newly generated output
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ retriever.py                 # Handles vector database and document retrieval
â”‚   â”œâ”€â”€ generator.py                 # LLM-based text generation logic
â”‚   â”œâ”€â”€ prompts.py                   # Prompt templates for RAG generation
â”‚   â””â”€â”€ main.py                      # Entry point for the AI agent
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.yaml                # Model parameters and paths
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # Project documentation
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/analytics-requirements-ai-agent.git
cd analytics-requirements-ai-agent
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure Settings
Update `config/settings.yaml` with your preferred:
- LLM provider (e.g., OpenAI, Anthropic, or local model)
- Vector store backend (FAISS, Chroma, etc.)
- Paths to your historical and generated requirements

### 4. Run the Agent
```bash
python src/main.py
```

---

## ğŸ§© Example Workflow

1. Load historical analytics requirements into the `data/historical_requirements/` folder.  
2. The agent indexes these using a vector database.  
3. You provide a prompt (e.g., *â€œGenerate analytics requirements for a new marketing campaign dashboard.â€*).  
4. The model retrieves relevant past requirements and generates a new, context-aware spec.  
5. The new output is stored under `data/generated_requirements/`.

---

## âš™ï¸ Tech Stack

- **Python 3.9+**
- **LangChain** for orchestration  
- **OpenAI / Azure OpenAI / Local LLMs** for generation  
- **FAISS or Chroma** for retrieval  
- **YAML + JSON** for configuration and data handling  

---

## ğŸ§  Future Enhancements

- Add semantic search UI  
- Integrate with Jira or Confluence for auto-documentation  
- Implement evaluation metrics for generated requirement quality  
- Support fine-tuning on domain-specific datasets  

---

## ğŸ“„ License

MIT License Â© 2025 [Your Name]

---

## ğŸ¤ Contributing

Contributions are welcome!  
Please open an issue or submit a pull request for improvements or new features.

---

## ğŸ’¬ Example Prompt

```text
Generate analytics requirements for an e-commerce sales performance dashboard.
```

**Example Output:**
```yaml
title: E-Commerce Sales Performance Dashboard
description: Provides real-time insights into sales performance by category, region, and marketing channel.
requirements:
  - Enable daily data refresh via ETL pipeline
  - Display sales KPIs (Revenue, Orders, AOV)
  - Include filters for date, category, and region
  - Integrate with Google Analytics and internal CRM
```
